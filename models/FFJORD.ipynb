{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as tforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "\"\"\" PROXIMAL IMPORTS \"\"\"\n",
    "sys.path.append('../../')\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from proxNode.lib.prox.adjoint import odeint_adjoint as odeint_prox\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" FFJORD IMPORTS \"\"\"\n",
    "from .wrappers.cnf_regularization import RegularizedODEfunc\n",
    "\n",
    "import proxNode.lib.layers as layers\n",
    "import proxNode.lib.utils as utils\n",
    "import proxNode.lib.odenvp as odenvp\n",
    "import proxNode.lib.multiscale_parallel as multiscale_parallel\n",
    "\n",
    "from train_misc import standard_normal_logprob\n",
    "from train_misc import set_cnf_options, count_nfe, count_parameters, count_total_time\n",
    "from train_misc import add_spectral_norm, spectral_norm_power_iteration\n",
    "from train_misc import create_regularization_fns, get_regularization, append_regularization_to_log\n",
    "\n",
    "__all__ = [\"CNF\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual Adjustment of Proximal Solver in the Forward Block Below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNF(nn.Module):\n",
    "    def __init__(self, odefunc, T=1.0, train_T=False, regularization_fns=None, solver='dopri5', atol=1e-5, rtol=1e-5):\n",
    "        super(CNF, self).__init__()\n",
    "        if train_T:\n",
    "            self.register_parameter(\"sqrt_end_time\", nn.Parameter(torch.sqrt(torch.tensor(T))))\n",
    "        else:\n",
    "            self.register_buffer(\"sqrt_end_time\", torch.sqrt(torch.tensor(T)))\n",
    "\n",
    "        nreg = 0\n",
    "        if regularization_fns is not None:\n",
    "            odefunc = RegularizedODEfunc(odefunc, regularization_fns)\n",
    "            nreg = len(regularization_fns)\n",
    "        self.odefunc = odefunc\n",
    "        self.nreg = nreg\n",
    "        self.regularization_states = None\n",
    "        self.solver = solver\n",
    "        self.atol = atol\n",
    "        self.rtol = rtol\n",
    "        self.test_solver = solver\n",
    "        self.test_atol = atol\n",
    "        self.test_rtol = rtol\n",
    "        self.solver_options = {}\n",
    "\n",
    "    def forward(self, z, logpz=None, integration_times=None, reverse=False):\n",
    "\n",
    "        if logpz is None:\n",
    "            _logpz = torch.zeros(z.shape[0], 1).to(z)\n",
    "        else:\n",
    "            _logpz = logpz\n",
    "\n",
    "        if integration_times is None:\n",
    "            integration_times = torch.tensor([0.0, self.sqrt_end_time * self.sqrt_end_time]).to(z)\n",
    "        if reverse:\n",
    "            integration_times = _flip(integration_times, 0)\n",
    "\n",
    "        # Refresh the odefunc statistics.\n",
    "        self.odefunc.before_odeint()\n",
    "\n",
    "        # Add regularization states.\n",
    "        reg_states = tuple(torch.tensor(0).to(z) for _ in range(self.nreg))\n",
    "\n",
    "        if self.training:\n",
    "            if self.solver == 'dopri5':\n",
    "                state_t = odeint(\n",
    "                   self.odefunc,\n",
    "                   (z, _logpz) + reg_states,\n",
    "                   integration_times.to(z),\n",
    "                   atol=self.atol,\n",
    "                   rtol=self.rtol,\n",
    "                   method=self.solver,\n",
    "                   options=self.solver_options,\n",
    "                )\n",
    "            elif self.solver == 'proximal':  #### PROXIMAL ADJUSTMENTS HERE\n",
    "                state_t = odeint(\n",
    "                    self.odefunc,\n",
    "                    (z, _logpz) + reg_states,\n",
    "                    integration_times.to(z),\n",
    "                    opt_method='fletch_reeves',\n",
    "                    prox_method='bdf4',\n",
    "                    int_step=.2,\n",
    "                    opt_step=.3,\n",
    "                    adjoint_options={'device':'cuda:0', 'opt_iters':60, 'tol':.01, 'grad_tol':.01}\n",
    "                )\n",
    "            else:\n",
    "                raise Exception('CNF solver not in [dopri5,proximal]')\n",
    "        else:\n",
    "            if self.solver == 'dopri5':\n",
    "                state_t = odeint(\n",
    "                    self.odefunc,\n",
    "                    (z, _logpz),\n",
    "                    integration_times.to(z),\n",
    "                    atol=self.test_atol,\n",
    "                    rtol=self.test_rtol,\n",
    "                    method=self.test_solver,\n",
    "                )\n",
    "            elif self.solver == 'proximal':  #### PROXIMAL ADJUSTMENTS HERE\n",
    "                state_t = odeint(\n",
    "                    self.odefunc,\n",
    "                        (z, _logpz) + reg_states,\n",
    "                        integration_times.to(z),\n",
    "                        opt_method='fletch_reeves',\n",
    "                        prox_method='bdf4',\n",
    "                        int_step=.2,\n",
    "                        opt_step=.3,\n",
    "                        adjoint_options={'device':'cuda:0', 'opt_iters':60, 'tol':.01, 'grad_tol':.01}\n",
    "                )\n",
    "            else:\n",
    "                raise Exception('CNF solver not in [dopri5,proximal]')\n",
    "\n",
    "        if len(integration_times) == 2:\n",
    "            state_t = tuple(s[1] for s in state_t)\n",
    "\n",
    "        z_t, logpz_t = state_t[:2]\n",
    "        self.regularization_states = state_t[2:]\n",
    "\n",
    "        if logpz is not None:\n",
    "            return z_t, logpz_t\n",
    "        else:\n",
    "            return z_t\n",
    "\n",
    "    def get_regularization_states(self):\n",
    "        reg_states = self.regularization_states\n",
    "        self.regularization_states = None\n",
    "        return reg_states\n",
    "\n",
    "    def num_evals(self):\n",
    "        return self.odefunc._num_evals.item()\n",
    "\n",
    "\n",
    "def _flip(x, dim):\n",
    "    indices = [slice(None)] * x.dim()\n",
    "    indices[dim] = torch.arange(x.size(dim) - 1, -1, -1, dtype=torch.long, device=x.device)\n",
    "    return x[tuple(indices)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "SOLVERS = [\"dopri5\", 'proximal']\n",
    "parser = argparse.ArgumentParser(\"Continuous Normalizing Flow\")\n",
    "parser.add_argument(\"--data\", choices=[\"mnist\", \"svhn\", \"cifar10\", 'lsun_church'], type=str, default=\"mnist\")\n",
    "parser.add_argument(\"--dims\", type=str, default=\"64,64,64\")\n",
    "parser.add_argument(\"--strides\", type=str, default=\"1,1,1,1\")\n",
    "parser.add_argument(\"--num_blocks\", type=int, default=2, help='Number of stacked CNFs.')\n",
    "\n",
    "parser.add_argument(\"--conv\", type=eval, default=True, choices=[True, False])\n",
    "parser.add_argument(\n",
    "    \"--layer_type\", type=str, default=\"concat\",\n",
    "    choices=[\"ignore\", \"concat\", \"concat_v2\", \"squash\", \"concatsquash\", \"concatcoord\", \"hyper\", \"blend\"]\n",
    ")\n",
    "parser.add_argument(\"--divergence_fn\", type=str, default=\"approximate\", choices=[\"brute_force\", \"approximate\"])\n",
    "parser.add_argument(\n",
    "    \"--nonlinearity\", type=str, default=\"softplus\", choices=[\"tanh\", \"relu\", \"softplus\", \"elu\", \"swish\"]\n",
    ")\n",
    "parser.add_argument('--solver', type=str, default='dopri5', choices=SOLVERS)\n",
    "parser.add_argument('--atol', type=float, default=1e-5)\n",
    "parser.add_argument('--rtol', type=float, default=1e-7)\n",
    "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
    "\n",
    "parser.add_argument('--test_solver', type=str, default=None, choices=SOLVERS + [None])\n",
    "parser.add_argument('--test_atol', type=float, default=None)\n",
    "parser.add_argument('--test_rtol', type=float, default=None)\n",
    "\n",
    "parser.add_argument(\"--imagesize\", type=int, default=None)\n",
    "parser.add_argument(\"--alpha\", type=float, default=1e-6)\n",
    "parser.add_argument('--time_length', type=float, default=1.0)\n",
    "parser.add_argument('--train_T', type=eval, default=True)\n",
    "\n",
    "parser.add_argument(\"--num_epochs\", type=int, default=10)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=200)\n",
    "parser.add_argument(\n",
    "    \"--batch_size_schedule\", type=str, default=\"\", help=\"Increases the batchsize at every given epoch, dash separated.\"\n",
    ")\n",
    "parser.add_argument(\"--test_batch_size\", type=int, default=200)\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "parser.add_argument(\"--warmup_iters\", type=float, default=1000)\n",
    "parser.add_argument(\"--weight_decay\", type=float, default=0.0)\n",
    "parser.add_argument(\"--spectral_norm_niter\", type=int, default=10)\n",
    "\n",
    "parser.add_argument(\"--add_noise\", type=eval, default=True, choices=[True, False])\n",
    "parser.add_argument(\"--batch_norm\", type=eval, default=False, choices=[True, False])\n",
    "parser.add_argument('--residual', type=eval, default=False, choices=[True, False])\n",
    "parser.add_argument('--autoencode', type=eval, default=False, choices=[True, False])\n",
    "parser.add_argument('--rademacher', type=eval, default=True, choices=[True, False])\n",
    "parser.add_argument('--spectral_norm', type=eval, default=False, choices=[True, False])\n",
    "parser.add_argument('--multiscale', type=eval, default=True, choices=[True, False])\n",
    "parser.add_argument('--parallel', type=eval, default=False, choices=[True, False])\n",
    "\n",
    "# Regularizations\n",
    "parser.add_argument('--l1int', type=float, default=None, help=\"int_t ||f||_1\")\n",
    "parser.add_argument('--l2int', type=float, default=None, help=\"int_t ||f||_2\")\n",
    "parser.add_argument('--dl2int', type=float, default=None, help=\"int_t ||f^T df/dt||_2\")\n",
    "parser.add_argument('--JFrobint', type=float, default=None, help=\"int_t ||df/dx||_F\")\n",
    "parser.add_argument('--JdiagFrobint', type=float, default=None, help=\"int_t ||df_i/dx_i||_F\")\n",
    "parser.add_argument('--JoffdiagFrobint', type=float, default=None, help=\"int_t ||df/dx - df_i/dx_i||_F\")\n",
    "\n",
    "parser.add_argument(\"--time_penalty\", type=float, default=0, help=\"Regularization on the end_time.\")\n",
    "parser.add_argument(\n",
    "    \"--max_grad_norm\", type=float, default=1e10,\n",
    "    help=\"Max norm of graidents (default is just stupidly high to avoid any clipping)\"\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--begin_epoch\", type=int, default=1)\n",
    "parser.add_argument(\"--resume\", type=str, default=None)\n",
    "parser.add_argument(\"--save\", type=str, default=\"experiments/cnf\")\n",
    "parser.add_argument(\"--val_freq\", type=int, default=1)\n",
    "parser.add_argument(\"--log_freq\", type=int, default=10)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# logger\n",
    "utils.makedirs(args.save)\n",
    "logger = utils.get_logger(logpath=os.path.join(args.save, 'logs'), filepath=os.path.abspath(__file__))\n",
    "\n",
    "if args.layer_type == \"blend\":\n",
    "    logger.info(\"!! Setting time_length from None to 1.0 due to use of Blend layers.\")\n",
    "    args.time_length = 1.0\n",
    "\n",
    "logger.info(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_noise(x):\n",
    "    \"\"\"\n",
    "    [0, 1] -> [0, 255] -> add noise -> [0, 1]\n",
    "    \"\"\"\n",
    "    if args.add_noise:\n",
    "        noise = x.new().resize_as_(x).uniform_()\n",
    "        x = x * 255 + noise\n",
    "        x = x / 256\n",
    "    return x\n",
    "\n",
    "\n",
    "def update_lr(optimizer, itr):\n",
    "    iter_frac = min(float(itr + 1) / max(args.warmup_iters, 1), 1.0)\n",
    "    lr = args.lr * iter_frac\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "\n",
    "def get_train_loader(train_set, epoch):\n",
    "    if args.batch_size_schedule != \"\":\n",
    "        epochs = [0] + list(map(int, args.batch_size_schedule.split(\"-\")))\n",
    "        n_passed = sum(np.array(epochs) <= epoch)\n",
    "        current_batch_size = int(args.batch_size * n_passed)\n",
    "    else:\n",
    "        current_batch_size = args.batch_size\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set, batch_size=current_batch_size, shuffle=True, drop_last=True, pin_memory=True\n",
    "    )\n",
    "    logger.info(\"===> Using batch size {}. Total {} iterations/epoch.\".format(current_batch_size, len(train_loader)))\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def get_dataset(args):\n",
    "    trans = lambda im_size: tforms.Compose([tforms.Resize(im_size), tforms.ToTensor(), add_noise])\n",
    "\n",
    "    if args.data == \"mnist\":\n",
    "        im_dim = 1\n",
    "        im_size = 28 if args.imagesize is None else args.imagesize\n",
    "        train_set = dset.MNIST(root=\"./data\", train=True, transform=trans(im_size), download=True)\n",
    "        test_set = dset.MNIST(root=\"./data\", train=False, transform=trans(im_size), download=True)\n",
    "    elif args.data == \"svhn\":\n",
    "        im_dim = 3\n",
    "        im_size = 32 if args.imagesize is None else args.imagesize\n",
    "        train_set = dset.SVHN(root=\"./data\", split=\"train\", transform=trans(im_size), download=True)\n",
    "        test_set = dset.SVHN(root=\"./data\", split=\"test\", transform=trans(im_size), download=True)\n",
    "    elif args.data == \"cifar10\":\n",
    "        im_dim = 3\n",
    "        im_size = 32 if args.imagesize is None else args.imagesize\n",
    "        train_set = dset.CIFAR10(\n",
    "            root=\"./data\", train=True, transform=tforms.Compose([\n",
    "                tforms.Resize(im_size),\n",
    "                tforms.RandomHorizontalFlip(),\n",
    "                tforms.ToTensor(),\n",
    "                add_noise,\n",
    "            ]), download=True\n",
    "        )\n",
    "        test_set = dset.CIFAR10(root=\"./data\", train=False, transform=trans(im_size), download=True)\n",
    "    elif args.data == 'celeba':\n",
    "        im_dim = 3\n",
    "        im_size = 64 if args.imagesize is None else args.imagesize\n",
    "        train_set = dset.CelebA(\n",
    "            train=True, transform=tforms.Compose([\n",
    "                tforms.ToPILImage(),\n",
    "                tforms.Resize(im_size),\n",
    "                tforms.RandomHorizontalFlip(),\n",
    "                tforms.ToTensor(),\n",
    "                add_noise,\n",
    "            ])\n",
    "        )\n",
    "        test_set = dset.CelebA(\n",
    "            train=False, transform=tforms.Compose([\n",
    "                tforms.ToPILImage(),\n",
    "                tforms.Resize(im_size),\n",
    "                tforms.ToTensor(),\n",
    "                add_noise,\n",
    "            ])\n",
    "        )\n",
    "    elif args.data == 'lsun_church':\n",
    "        im_dim = 3\n",
    "        im_size = 64 if args.imagesize is None else args.imagesize\n",
    "        train_set = dset.LSUN(\n",
    "            'data', ['church_outdoor_train'], transform=tforms.Compose([\n",
    "                tforms.Resize(96),\n",
    "                tforms.RandomCrop(64),\n",
    "                tforms.Resize(im_size),\n",
    "                tforms.ToTensor(),\n",
    "                add_noise,\n",
    "            ])\n",
    "        )\n",
    "        test_set = dset.LSUN(\n",
    "            'data', ['church_outdoor_val'], transform=tforms.Compose([\n",
    "                tforms.Resize(96),\n",
    "                tforms.RandomCrop(64),\n",
    "                tforms.Resize(im_size),\n",
    "                tforms.ToTensor(),\n",
    "                add_noise,\n",
    "            ])\n",
    "        )\n",
    "    data_shape = (im_dim, im_size, im_size)\n",
    "    if not args.conv:\n",
    "        data_shape = (im_dim * im_size * im_size,)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_set, batch_size=args.test_batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "    return train_set, test_loader, data_shape\n",
    "\n",
    "\n",
    "def compute_bits_per_dim(x, model):\n",
    "    zero = torch.zeros(x.shape[0], 1).to(x)\n",
    "\n",
    "    # Don't use data parallelize if batch size is small.\n",
    "    # if x.shape[0] < 200:\n",
    "    #     model = model.module\n",
    "\n",
    "    z, delta_logp = model(x, zero)  # run model forward\n",
    "\n",
    "    logpz = standard_normal_logprob(z).view(z.shape[0], -1).sum(1, keepdim=True)  # logp(z)\n",
    "    logpx = logpz - delta_logp\n",
    "\n",
    "    logpx_per_dim = torch.sum(logpx) / x.nelement()  # averaged over batches\n",
    "    bits_per_dim = -(logpx_per_dim - np.log(256)) / np.log(2)\n",
    "\n",
    "    return bits_per_dim\n",
    "\n",
    "\n",
    "def create_model(args, data_shape, regularization_fns):\n",
    "    hidden_dims = tuple(map(int, args.dims.split(\",\")))\n",
    "    strides = tuple(map(int, args.strides.split(\",\")))\n",
    "\n",
    "    if args.multiscale:\n",
    "        model = odenvp.ODENVP(\n",
    "            (args.batch_size, *data_shape),\n",
    "            n_blocks=args.num_blocks,\n",
    "            intermediate_dims=hidden_dims,\n",
    "            nonlinearity=args.nonlinearity,\n",
    "            alpha=args.alpha,\n",
    "            cnf_kwargs={\"T\": args.time_length, \"train_T\": args.train_T, \"regularization_fns\": regularization_fns},\n",
    "        )\n",
    "    elif args.parallel:\n",
    "        model = multiscale_parallel.MultiscaleParallelCNF(\n",
    "            (args.batch_size, *data_shape),\n",
    "            n_blocks=args.num_blocks,\n",
    "            intermediate_dims=hidden_dims,\n",
    "            alpha=args.alpha,\n",
    "            time_length=args.time_length,\n",
    "        )\n",
    "    else:\n",
    "        if args.autoencode:\n",
    "\n",
    "            def build_cnf():\n",
    "                autoencoder_diffeq = layers.AutoencoderDiffEqNet(\n",
    "                    hidden_dims=hidden_dims,\n",
    "                    input_shape=data_shape,\n",
    "                    strides=strides,\n",
    "                    conv=args.conv,\n",
    "                    layer_type=args.layer_type,\n",
    "                    nonlinearity=args.nonlinearity,\n",
    "                )\n",
    "                odefunc = layers.AutoencoderODEfunc(\n",
    "                    autoencoder_diffeq=autoencoder_diffeq,\n",
    "                    divergence_fn=args.divergence_fn,\n",
    "                    residual=args.residual,\n",
    "                    rademacher=args.rademacher,\n",
    "                )\n",
    "                cnf = layers.CNF(\n",
    "                    odefunc=odefunc,\n",
    "                    T=args.time_length,\n",
    "                    regularization_fns=regularization_fns,\n",
    "                    solver=args.solver,\n",
    "                )\n",
    "                return cnf\n",
    "        else:\n",
    "\n",
    "            def build_cnf():\n",
    "                diffeq = layers.ODEnet(\n",
    "                    hidden_dims=hidden_dims,\n",
    "                    input_shape=data_shape,\n",
    "                    strides=strides,\n",
    "                    conv=args.conv,\n",
    "                    layer_type=args.layer_type,\n",
    "                    nonlinearity=args.nonlinearity,\n",
    "                )\n",
    "                odefunc = layers.ODEfunc(\n",
    "                    diffeq=diffeq,\n",
    "                    divergence_fn=args.divergence_fn,\n",
    "                    residual=args.residual,\n",
    "                    rademacher=args.rademacher,\n",
    "                )\n",
    "                cnf = layers.CNF(\n",
    "                    odefunc=odefunc,\n",
    "                    T=args.time_length,\n",
    "                    train_T=args.train_T,\n",
    "                    regularization_fns=regularization_fns,\n",
    "                    solver=args.solver,\n",
    "                )\n",
    "                return cnf\n",
    "\n",
    "        chain = [layers.LogitTransform(alpha=args.alpha)] if args.alpha > 0 else [layers.ZeroMeanTransform()]\n",
    "        chain = chain + [build_cnf() for _ in range(args.num_blocks)]\n",
    "        if args.batch_norm:\n",
    "            chain.append(layers.MovingBatchNorm2d(data_shape[0]))\n",
    "        model = layers.SequentialFlow(chain)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get deivce\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "cvt = lambda x: x.type(torch.float32).to(device, non_blocking=True)\n",
    "\n",
    "# load dataset\n",
    "train_set, test_loader, data_shape = get_dataset(args)\n",
    "\n",
    "# build model\n",
    "regularization_fns, regularization_coeffs = create_regularization_fns(args)\n",
    "model = create_model(args, data_shape, regularization_fns)\n",
    "\n",
    "if args.spectral_norm: add_spectral_norm(model, logger)\n",
    "set_cnf_options(args, model)\n",
    "\n",
    "logger.info(model)\n",
    "logger.info(\"Number of trainable parameters: {}\".format(count_parameters(model)))\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "# restore parameters\n",
    "if args.resume is not None:\n",
    "    checkpt = torch.load(args.resume, map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(checkpt[\"state_dict\"])\n",
    "    if \"optim_state_dict\" in checkpt.keys():\n",
    "        optimizer.load_state_dict(checkpt[\"optim_state_dict\"])\n",
    "        # Manually move optimizer state to device.\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if torch.is_tensor(v):\n",
    "                    state[k] = cvt(v)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "# For visualization.\n",
    "fixed_z = cvt(torch.randn(100, *data_shape))\n",
    "\n",
    "time_meter = utils.RunningAverageMeter(0.97)\n",
    "loss_meter = utils.RunningAverageMeter(0.97)\n",
    "steps_meter = utils.RunningAverageMeter(0.97)\n",
    "bkwd_steps_meter = utils.RunningAverageMeter(0.97)\n",
    "grad_meter = utils.RunningAverageMeter(0.97)\n",
    "tt_meter = utils.RunningAverageMeter(0.97)\n",
    "\n",
    "if args.spectral_norm and not args.resume: spectral_norm_power_iteration(model, 500)\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "itr = 0\n",
    "for epoch in range(args.begin_epoch, args.num_epochs + 1):\n",
    "    model.train()\n",
    "    train_loader = get_train_loader(train_set, epoch)\n",
    "    for _, (x, y) in enumerate(train_loader):\n",
    "        start = time.time()\n",
    "        update_lr(optimizer, itr)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if not args.conv:\n",
    "            x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # cast data and move to device\n",
    "        x = cvt(x)\n",
    "        # compute loss\n",
    "        loss = compute_bits_per_dim(x, model)\n",
    "        if regularization_coeffs:\n",
    "            reg_states = get_regularization(model, regularization_coeffs)\n",
    "            reg_loss = sum(\n",
    "                reg_state * coeff for reg_state, coeff in zip(reg_states, regularization_coeffs) if coeff != 0\n",
    "            )\n",
    "            loss = loss + reg_loss\n",
    "        total_time = count_total_time(model)\n",
    "        loss = loss + total_time * args.time_penalty\n",
    "        \n",
    "        fwd_steps = count_nfe(model)\n",
    "\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if args.spectral_norm: spectral_norm_power_iteration(model, args.spectral_norm_niter)\n",
    "\n",
    "        total_steps = count_nfe(model)\n",
    "        time_meter.update(time.time() - start)\n",
    "        loss_meter.update(loss.item())\n",
    "        steps_meter.update(fwd_steps)\n",
    "        bkwd_steps_meter.update(total_steps-fwd_steps)\n",
    "        grad_meter.update(grad_norm)\n",
    "        tt_meter.update(total_time)\n",
    "\n",
    "        if itr % args.log_freq == 0:\n",
    "            log_message = (\n",
    "                \"Iter {:04d} | Time {:.4f}({:.4f}) | Bit/dim {:.4f}({:.4f}) | \"\n",
    "                \"NFE-F {:.0f}({:.2f}) | NFE-B {:.0f}({:.2f}) | Grad Norm {:.4f}({:.4f}) | Total Time {:.2f}({:.2f})\".format(\n",
    "                    itr, time_meter.val, time_meter.avg, loss_meter.val, loss_meter.avg, steps_meter.val,\n",
    "                    steps_meter.avg, bkwd_steps_meter.val, bkwd_steps_meter.avg, grad_meter.val, grad_meter.avg, tt_meter.val, tt_meter.avg\n",
    "                )\n",
    "            )\n",
    "            if regularization_coeffs:\n",
    "                log_message = append_regularization_to_log(log_message, regularization_fns, reg_states)\n",
    "            logger.info(log_message)\n",
    "\n",
    "        itr += 1\n",
    "\n",
    "    # compute test loss\n",
    "    model.eval()\n",
    "    if epoch % args.val_freq == 0:\n",
    "        with torch.no_grad():\n",
    "            start = time.time()\n",
    "            logger.info(\"validating...\")\n",
    "            losses = []\n",
    "            for (x, y) in test_loader:\n",
    "                if not args.conv:\n",
    "                    x = x.view(x.shape[0], -1)\n",
    "                x = cvt(x)\n",
    "                loss = compute_bits_per_dim(x, model)\n",
    "                losses.append(loss)\n",
    "\n",
    "            loss = torch.mean(torch.Tensor(losses))\n",
    "            logger.info(\"Epoch {:04d} | Time {:.4f}, Bit/dim {:.4f}\".format(epoch, time.time() - start, loss))\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                utils.makedirs(args.save)\n",
    "                torch.save({\n",
    "                    \"args\": args,\n",
    "                    \"state_dict\": model.module.state_dict() if torch.cuda.is_available() else model.state_dict(),\n",
    "                    \"optim_state_dict\": optimizer.state_dict(),\n",
    "                }, os.path.join(args.save, \"checkpt.pth\"))\n",
    "\n",
    "    # visualize samples and density\n",
    "    with torch.no_grad():\n",
    "        fig_filename = os.path.join(args.save, \"figs\", \"{:04d}.jpg\".format(epoch))\n",
    "        utils.makedirs(os.path.dirname(fig_filename))\n",
    "        generated_samples = model(fixed_z, reverse=True).view(-1, *data_shape)\n",
    "        save_image(generated_samples, fig_filename, nrow=10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
